{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsong-77/transformer-practice/blob/main/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqjTofOwN64k"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.11.3\n",
        "!pip install datasets\n",
        "!pip install umap-learn==0.5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QfJTAZu70XD"
      },
      "outputs": [],
      "source": [
        "# load datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "emotions = load_dataset(\"emotion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP94t9qXs7a_"
      },
      "outputs": [],
      "source": [
        "# data\n",
        "import pandas as pd\n",
        "\n",
        "emotions.set_format(type=\"pandas\")\n",
        "df = emotions[\"train\"][:]\n",
        "\n",
        "def label_int2str(row):\n",
        "  return emotions[\"train\"].features[\"label\"].int2str(row)\n",
        "\n",
        "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9lRxEFTueAE"
      },
      "outputs": [],
      "source": [
        "# data class distribution\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
        "plt.title(\"Frequency of Classes\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQnRnMwwvWQg"
      },
      "outputs": [],
      "source": [
        "# data how long\n",
        "df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\n",
        "df.boxplot(\"Words Per Tweet\", by=\"label_name\", grid=False, showfliers=False, color=\"black\")\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC1rcFgnwJMC"
      },
      "outputs": [],
      "source": [
        "emotions.reset_format()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxj0adlOY3-k"
      },
      "outputs": [],
      "source": [
        "# tokenizing\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize(batch):\n",
        "  return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
        "\n",
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\n",
        "print(emotions_encoded[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buYEvUUiF_P8"
      },
      "outputs": [],
      "source": [
        "# method1: feature extraction\n",
        "import torch\n",
        "from transformers import AutoModel\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
        "\n",
        "def extract_hidden_states(batch):\n",
        "  inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
        "\n",
        "  with torch.no_grad():\n",
        "    last_hidden_state = model(**inputs).last_hidden_state\n",
        "\n",
        "  return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}\n",
        "\n",
        "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
        "X_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\n",
        "y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n",
        "y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])"
      ],
      "metadata": {
        "id": "430Cx1y0h7mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoiIeGLTAWCb"
      },
      "outputs": [],
      "source": [
        "# classifier head\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression(max_iter=3000)\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_clf.score(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iB-_byZ9kB8"
      },
      "outputs": [],
      "source": [
        "# visualizing the train set\n",
        "# dimensions to 2D\n",
        "from umap import UMAP\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Scale features to [0,1] range\n",
        "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
        "# Initialize and fit UMAP\n",
        "mapper = UMAP(n_components=2, metric=\"cosine\").fit(X_scaled)\n",
        "# Create a DataFrame of 2D embeddings\n",
        "df_emb = pd.DataFrame(mapper.embedding_, columns=[\"X\", \"Y\"])\n",
        "df_emb[\"label\"] = y_train\n",
        "df_emb.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXNyC1ZH-Ls3"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(7,5))\n",
        "axes = axes.flatten()\n",
        "cmaps = [\"Greys\", \"Blues\", \"Oranges\", \"Reds\", \"Purples\", \"Greens\"]\n",
        "labels = emotions[\"train\"].features[\"label\"].names\n",
        "\n",
        "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
        "    df_emb_sub = df_emb.query(f\"label == {i}\")\n",
        "    axes[i].hexbin(df_emb_sub[\"X\"], df_emb_sub[\"Y\"], cmap=cmap,\n",
        "                   gridsize=20, linewidths=(0,))\n",
        "    axes[i].set_title(label)\n",
        "    axes[i].set_xticks([]), axes[i].set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_kKNRW--eGy"
      },
      "outputs": [],
      "source": [
        "# confusion matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "    plt.title(\"Normalized confusion matrix\")\n",
        "    plt.show()\n",
        "\n",
        "labels = emotions[\"train\"].features[\"label\"].names\n",
        "y_preds = lr_clf.predict(X_valid)\n",
        "plot_confusion_matrix(y_preds, y_valid, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "462aoH0b-zXt"
      },
      "outputs": [],
      "source": [
        "# method2: fine tuning\n",
        "# model\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "num_labels = 6\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels).to(device)\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "# training args\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 64\n",
        "logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  num_train_epochs=2,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  weight_decay=0.01,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  push_to_hub=False,\n",
        "                                  log_level=\"error\")\n",
        "\n",
        "# trainer\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model=model,\n",
        "                  args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=emotions_encoded[\"train\"],\n",
        "                  eval_dataset=emotions_encoded[\"validation\"],\n",
        "                  tokenizer=tokenizer)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7B4XiCtEZV0"
      },
      "outputs": [],
      "source": [
        "# prediction result\n",
        "preds_output = trainer.predict(emotions_encoded[\"validation\"])\n",
        "preds_output.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMF-Ig2dE--o"
      },
      "outputs": [],
      "source": [
        "# confusion matrix\n",
        "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
        "plot_confusion_matrix(y_preds, y_valid, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipPS8PW5FXxX"
      },
      "outputs": [],
      "source": [
        "# error analysis"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs6L/wHkRUXzs6tt0GyKOX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}