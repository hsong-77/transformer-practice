{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOH7bWjD8PCdJAbj31ZWmvZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsong-77/transformer-practice/blob/main/model-compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvkrTRsxcEVD"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "clinc = load_dataset(\"clinc_oos\", \"plus\")\n",
        "clinc"
      ],
      "metadata": {
        "id": "D6BbrdsW7U6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = clinc[\"test\"][42]\n",
        "sample"
      ],
      "metadata": {
        "id": "8cje8eP58Mjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents = clinc[\"test\"].features[\"intent\"]\n",
        "intents.int2str(sample[\"intent\"])"
      ],
      "metadata": {
        "id": "3ZROBXKn8QXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "pipe = pipeline(\"text-classification\", model=ckpt)"
      ],
      "metadata": {
        "id": "ihvIbEGy4Qev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\"\"\"\n",
        "pipe(query)"
      ],
      "metadata": {
        "id": "0nkLcqum45dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "from pathlib import Path\n",
        "from time import perf_counter\n",
        "\n",
        "accuracy_score = load_metric(\"accuracy\")\n",
        "\n",
        "class PerformanceBenchmark:\n",
        "  def __init__(self, pipeline, dataset, optim_type=\"BERT baseline\"):\n",
        "    self.pipeline = pipeline\n",
        "    self.dataset = dataset\n",
        "    self.optim_type = optim_type\n",
        "\n",
        "  def compute_accuracy(self):\n",
        "    preds, labels = [], []\n",
        "    for example in self.dataset:\n",
        "      pred = self.pipeline(example[\"text\"])[0][\"label\"]\n",
        "      label = example[\"intent\"]\n",
        "      preds.append(intents.str2int(pred))\n",
        "      labels.append(label)\n",
        "\n",
        "    accuracy = accuracy_score.compute(predictions=preds, references=labels)\n",
        "    print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
        "    return accuracy\n",
        "\n",
        "  def compute_size(self):\n",
        "    state_dict = self.pipeline.model.state_dict()\n",
        "    tmp_path = Path(\"model.pt\")\n",
        "    torch.save(state_dict, tmp_path)\n",
        "    size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
        "    # delete tmp path\n",
        "    tmp_path.unlink()\n",
        "\n",
        "    print(f\"Model size (MB) - {size_mb:.2f}\")\n",
        "    return {\"size_mb\": size_mb}\n",
        "\n",
        "  def time_pipeline(self, query=\"What is the pin number for my account?\"):\n",
        "    latencies = []\n",
        "    # warm up\n",
        "    for _ in range(10):\n",
        "      _ = self.pipeline(query)\n",
        "      # timed run\n",
        "    for _ in range(100):\n",
        "      start_time = perf_counter()\n",
        "      _ = self.pipeline(query)\n",
        "      latency = perf_counter() - start_time\n",
        "      latencies.append(latency)\n",
        "    \n",
        "    time_avg_ms = 1000 * np.mean(latencies)\n",
        "    time_std_ms = 1000 * np.std(latencies)\n",
        "    print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
        "    return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
        "\n",
        "  def run_benchmark(self):\n",
        "    metrics = {}\n",
        "    metrics[self.optim_type] = self.compute_size()\n",
        "    metrics[self.optim_type].update(self.time_pipeline())\n",
        "    metrics[self.optim_type].update(self.compute_accuracy())\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "Lrgn2cJe53uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pb = PerformanceBenchmark(pipe, clinc[\"test\"])\n",
        "perf_metrics = pb.run_benchmark()"
      ],
      "metadata": {
        "id": "houMKbDc0IpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "class DistillationTrainingArguments(TrainingArguments):\n",
        "  def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.alpha = alpha\n",
        "    self.temperature = temperature"
      ],
      "metadata": {
        "id": "eU2_GX4aB1vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import Trainer\n",
        "\n",
        "class DistillationTrainer(Trainer):\n",
        "  def __init__(self, *args, teacher_model=None, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.teacher_model = teacher_model\n",
        "\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    outputs_stu = model(**inputs)\n",
        "    loss_ce = outputs_stu.loss\n",
        "    logits_stu = outputs_stu.logits\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs_tea = self.teacher_model(**inputs)\n",
        "      logits_tea = outputs_tea.logits\n",
        "    loss_fct = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    loss_kd = self.args.temperature ** 2 * loss_fct(F.log_softmax(logits_stu / self.args.temperature, dim=-1), F.softmax(logits_tea / self.args.temperature, dim=-1))\n",
        "\n",
        "    loss = self.args.alpha * loss_ce + (1 - self.args.alpha) * loss_kd\n",
        "    return (loss, outputs_stu) if return_outputs else loss"
      ],
      "metadata": {
        "id": "qyAj65fNCpAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "student_ckpt = \"distilbert-base-uncased\"\n",
        "student_tokenizer = AutoTokenizer.from_pretrained(student_ckpt)\n",
        "\n",
        "def tokenize_text(batch):\n",
        "  return student_tokenizer(batch[\"text\"], truncation=True)\n",
        "\n",
        "clinc_enc = clinc.map(tokenize_text, batched=True, remove_columns=[\"text\"])\n",
        "clinc_enc = clinc_enc.rename_column(\"intent\", \"labels\")\n",
        "clinc_enc"
      ],
      "metadata": {
        "id": "HR4O_m39GiCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "  predictions, labels = pred\n",
        "  predictions = np.argmax(predictions, axis=-1)\n",
        "  return accuracy_score.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "XKCbo8dpH-0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "batch_size = 48\n",
        "\n",
        "finetuned_ckpt = \"distilbert-base-uncased-finetuned-clinc\"\n",
        "student_training_args = DistillationTrainingArguments(output_dir=finetuned_ckpt, evaluation_strategy=\"epoch\",\n",
        "                                                      num_train_epochs=5, learning_rate=2e-5,\n",
        "                                                      per_device_train_batch_size=batch_size,\n",
        "                                                      per_device_eval_batch_size=batch_size,\n",
        "                                                      alpha=1, weight_decay=0.01, push_to_hub=False)\n",
        "\n",
        "id2label = pipe.model.config.id2label\n",
        "label2id = pipe.model.config.label2id\n",
        "\n",
        "num_labels = intents.num_classes\n",
        "student_config = AutoConfig.from_pretrained(student_ckpt, num_labels=num_labels,\n",
        "                                            id2label=id2label, label2id=label2id)"
      ],
      "metadata": {
        "id": "sAA6awL_oQmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models import distilbert\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def student_init():\n",
        "  return AutoModelForSequenceClassification.from_pretrained(student_ckpt, config=student_config).to(device)\n",
        "\n",
        "teacher_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(teacher_ckpt, num_labels=num_labels).to(device)\n",
        "\n",
        "distilbert_trainer = DistillationTrainer(model_init=student_init,\n",
        "                                         teacher_model=teacher_model, args=student_training_args,\n",
        "                                         train_dataset=clinc_enc[\"train\"], eval_dataset=clinc_enc[\"validation\"],\n",
        "                                         compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
        "\n",
        "distilbert_trainer.train()"
      ],
      "metadata": {
        "id": "h0UBCsoarY_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-classification\", model=distilbert_trainer.model, tokenizer=student_tokenizer)\n",
        "\n",
        "optim_type = \"DistilBERT\"\n",
        "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
        "perf_metrics.update(pb.run_benchmark())"
      ],
      "metadata": {
        "id": "Zv_abv6ju9B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def plot_metrics(perf_metrics, current_optim_type):\n",
        "  df = pd.DataFrame.from_dict(perf_metrics, orient='index')\n",
        "\n",
        "  for idx in df.index:\n",
        "    df_opt = df.loc[idx]\n",
        "    # Add a dashed circle around the current optimization type\n",
        "    if idx == current_optim_type:\n",
        "      plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100,\n",
        "                  alpha=0.5, s=df_opt[\"size_mb\"], label=idx, marker='$\\u25CC$')\n",
        "    else:\n",
        "      plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100,\n",
        "                        s=df_opt[\"size_mb\"], label=idx, alpha=0.5)\n",
        "\n",
        "  legend = plt.legend(bbox_to_anchor=(1,1))\n",
        "  for handle in legend.legendHandles:\n",
        "    handle.set_sizes([20])\n",
        "\n",
        "  plt.ylim(70,90)\n",
        "  # Use the slowest model to define the x-axis range\n",
        "  xlim = int(perf_metrics[\"BERT baseline\"][\"time_avg_ms\"] + 7)\n",
        "  plt.xlim(1, xlim)\n",
        "  plt.ylabel(\"Accuracy (%)\")\n",
        "  plt.xlabel(\"Average latency (ms)\")\n",
        "  plt.show()\n",
        "\n",
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "9tcgj3WmwJCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def hp_space(trial):\n",
        "  return {\"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n",
        "          \"alpha\": trial.suggest_float(\"alpha\", 0, 1),\n",
        "          \"temperature\": trial.suggest_int(\"temperature\", 2, 20)}\n",
        "\n",
        "best_run = distilbert_trainer.hyperparameter_search(n_trials=20, direction=\"maximize\", hp_space=hp_space)\n",
        "best_run"
      ],
      "metadata": {
        "id": "3q-8eNbWyaUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in best_run.hyperparameters.items():\n",
        "  setattr(student_training_args, k, v)\n",
        "\n",
        "distilled_ckpt = \"distilbert-base-uncased-distilled-clinc\"\n",
        "student_training_args.output_dir = distilled_ckpt\n",
        "\n",
        "distil_trainer = DistillationTrainer(model_init=student_init,\n",
        "                                     teacher_model=teacher_model, args=student_training_args,\n",
        "                                     train_dataset=clinc_enc['train'], eval_dataset=clinc_enc['validation'],\n",
        "                                     compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
        "\n",
        "distil_trainer.train()"
      ],
      "metadata": {
        "id": "xrmn4AtmztGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-classification\", model=distil_trainer.model, tokenizer=student_tokenizer)\n",
        "optim_type = \"Distillation\"\n",
        "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
        "perf_metrics.update(pb.run_benchmark())\n",
        "\n",
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "OKTYDY3M0yXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = pipe.model.state_dict()\n",
        "weights = state_dict[\"distilbert.transformer.layer.0.attention.out_lin.weight\"]\n",
        "plt.hist(weights.flatten().numpy(), bins=250, range=(-0.3,0.3), edgecolor=\"C0\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zOpzRKfd4isU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_point = 0\n",
        "scale = (weights.max() - weights.min()) / (127 - (-128))\n",
        "(weights / scale + zero_point).clamp(-128, 127).round().char()"
      ],
      "metadata": {
        "id": "bToLEfIo8zq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import quantize_per_tensor\n",
        "\n",
        "dtype = torch.qint8\n",
        "quantized_weights = quantize_per_tensor(weights, scale, zero_point, dtype)\n",
        "quantized_weights.int_repr()"
      ],
      "metadata": {
        "id": "SxjHgb_s9eyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "weights @ weights"
      ],
      "metadata": {
        "id": "A7Un8ghq-d-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import quantized\n",
        "from torch.nn.quantized import QFunctional\n",
        "\n",
        "q_fn = QFunctional()"
      ],
      "metadata": {
        "id": "sJpJ9NNB-stA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "q_fn.mul(quantized_weights, quantized_weights)"
      ],
      "metadata": {
        "id": "RjeruVVzeuKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.getsizeof(weights.storage()) / sys.getsizeof(quantized_weights.storage())"
      ],
      "metadata": {
        "id": "rB1NjK_Y_Yg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.quantization import quantize_dynamic\n",
        "\n",
        "model_quantized = quantize_dynamic(distil_trainer.model, {nn.Linear}, dtype=torch.qint8)"
      ],
      "metadata": {
        "id": "ze1J4MSwCOC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-classification\", model=model_quantized, tokenizer=student_tokenizer)\n",
        "optim_type = \"Distillation + quantization\"\n",
        "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
        "perf_metrics.update(pb.run_benchmark())"
      ],
      "metadata": {
        "id": "thWSZQ3yC3cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "AsASY8jLC7JQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}