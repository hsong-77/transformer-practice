{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT8lpNj5fC5Fh4YXZoJ7eG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsong-77/transformer-practice/blob/main/model-compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvkrTRsxcEVD"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "clinc = load_dataset(\"clinc_oos\", \"plus\")\n",
        "clinc"
      ],
      "metadata": {
        "id": "D6BbrdsW7U6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = clinc[\"test\"][42]\n",
        "sample"
      ],
      "metadata": {
        "id": "8cje8eP58Mjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents = clinc[\"test\"].features[\"intent\"]\n",
        "intents.int2str(sample[\"intent\"])"
      ],
      "metadata": {
        "id": "3ZROBXKn8QXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "pipe = pipeline(\"text-classification\", model=ckpt)"
      ],
      "metadata": {
        "id": "ihvIbEGy4Qev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\"\"\"\n",
        "pipe(query)"
      ],
      "metadata": {
        "id": "0nkLcqum45dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_metric\n",
        "from pathlib import Path\n",
        "\n",
        "accuracy_score = load_metric(\"accuracy\")\n",
        "\n",
        "class PerformanceBenchmark:\n",
        "  def __init__(self, pipeline, dataset, optim_type=\"BERT baseline\"):\n",
        "    self.pipeline = pipeline\n",
        "    self.dataset = dataset\n",
        "    self.optim_type = optim_type\n",
        "\n",
        "  def compute_accuracy(self):\n",
        "    preds, labels = [], []\n",
        "    for example in self.dataset:\n",
        "      pred = self.pipeline(example[\"text\"])[0][\"label\"]\n",
        "      label = example[\"intent\"]\n",
        "      preds.append(intents.str2int(pred))\n",
        "      labels.append(label)\n",
        "\n",
        "    accuracy = accuracy_score.compute(predictions=preds, references=labels)\n",
        "    print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
        "    return accuracy\n",
        "\n",
        "  def compute_size(self):\n",
        "    state_dict = self.pipeline.model.state_dict()\n",
        "    tmp_path = Path(\"model.pt\")\n",
        "    torch.save(state_dict, tmp_path)\n",
        "    size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
        "    # delete tmp path\n",
        "    tmp_path.unlink()\n",
        "\n",
        "    print(f\"Model size (MB) - {size_mb:.2f}\")\n",
        "    return {\"size_mb\": size_mb}\n",
        "\n",
        "  def time_pipeline(self):\n",
        "    pass\n",
        "\n",
        "  def run_benchmark(self):\n",
        "    metrics = {}\n",
        "    metrics[self.optim_type] = self.compute_size()\n",
        "    metrics[self.optim_type].update(self.time_pipeline())\n",
        "    metrics[self.optim_type].update(self.compute_accuracy())\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "Lrgn2cJe53uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "houMKbDc0IpI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}