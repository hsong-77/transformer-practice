{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMYX0kIZJcRqjt1GAWCJEB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsong-77/transformer-practice/blob/main/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FitwZcD3ZbAl"
      },
      "outputs": [],
      "source": [
        "!pip install transformers===4.11.3\n",
        "!pip install datasets\n",
        "!pip install seqeval==1.2.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import get_dataset_config_names\n",
        "\n",
        "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
        "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
      ],
      "metadata": {
        "id": "I50JkZhXXvOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
        "panx_subsets[:3]"
      ],
      "metadata": {
        "id": "KJ50H640YK-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "load_dataset(\"xtreme\", name=\"PAN-X.de\")"
      ],
      "metadata": {
        "id": "u0-awIeRYfuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from datasets import DatasetDict\n",
        "\n",
        "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
        "fracs = [0.629, 0.229, 0.084, 0.059]\n",
        "panx_ch = defaultdict(DatasetDict)\n",
        "\n",
        "for lang, frac in zip(langs, fracs):\n",
        "  ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
        "  for split in ds:\n",
        "    panx_ch[lang][split] = ds[split].shuffle(seed=0).select(range(int(frac * ds[split].num_rows)))"
      ],
      "metadata": {
        "id": "WiKaHxy3ZNLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs}, index=[\"Number of training examples\"])"
      ],
      "metadata": {
        "id": "rUH3PmSDbntV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "element = panx_ch[\"de\"][\"train\"][0]\n",
        "for key, value in element.items():\n",
        "  print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "id": "YPmnE_lIcO73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in panx_ch[\"de\"][\"train\"].features.items():\n",
        "  print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "id": "dneP2TiQdRm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
        "print(tags)"
      ],
      "metadata": {
        "id": "KvdJTAlBeF4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tag_names(batch):\n",
        "  return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
        "\n",
        "panx_de = panx_ch[\"de\"].map(create_tag_names)\n",
        "\n",
        "de_example = panx_de[\"train\"][0]\n",
        "pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]], ['Tokens', 'Tags'])"
      ],
      "metadata": {
        "id": "S2qloGG6ePnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "split2freqs = defaultdict(Counter)\n",
        "for split, dataset in panx_de.items():\n",
        "  for row in dataset[\"ner_tags_str\"]:\n",
        "    for tag in row:\n",
        "      if tag.startswith(\"B\"):\n",
        "        tag_type = tag.split(\"-\")[1]\n",
        "        split2freqs[split][tag_type] += 1\n",
        "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
      ],
      "metadata": {
        "id": "CVhdzs4OfgSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "bert_model_name = \"bert-base-cased\"\n",
        "xlmr_model_name = \"xlm-roberta-base\"\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
      ],
      "metadata": {
        "id": "yPV_6ugnoyTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Jack Sparrow loves New York!\"\n",
        "bert_tokens = bert_tokenizer(text).tokens()\n",
        "xlmr_tokens = xlmr_tokenizer(text).tokens()\n",
        "bert_tokens, xlmr_tokens"
      ],
      "metadata": {
        "id": "a1QiMs-1pHDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\".join(xlmr_tokens).replace(u\"\\u2581\", \" \")"
      ],
      "metadata": {
        "id": "i-r5cfc4tMqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaConfig\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
        "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
        "\n",
        "class XLMRobertaForTokenClassificaiton(RobertaPreTrainedModel):\n",
        "  config_class = XLMRobertaConfig\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super().__init__(config)\n",
        "    self.num_labels = config.num_labels\n",
        "    # model\n",
        "    self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
        "    # classification head\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    # weights\n",
        "    self.init_weights()\n",
        "\n",
        "  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
        "    # encode\n",
        "    outputs = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **kwargs)\n",
        "    # classify\n",
        "    sequence_output = self.dropout(outputs[0])\n",
        "    logits = self.classifier(sequence_output)\n",
        "    # losses\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "    #output\n",
        "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)"
      ],
      "metadata": {
        "id": "BMsq1AnOuRX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
        "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
      ],
      "metadata": {
        "id": "SW06CZk6EIJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,\n",
        "                                         num_labels=tags.num_classes,\n",
        "                                         id2label=index2tag, label2id=tag2index)"
      ],
      "metadata": {
        "id": "XGGhmyLqFRK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "xlmr_model = XLMRobertaForTokenClassificaiton.from_pretrained(xlmr_model_name, config=xlmr_config).to(device)"
      ],
      "metadata": {
        "id": "xKcrJqxyGmxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
        "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
      ],
      "metadata": {
        "id": "KXPd2mziHdtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = xlmr_model(input_ids.to(device)).logits\n",
        "predictions = torch.argmax(outputs, dim=-1)\n",
        "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
        "print(f\"Shape of outputs: {outputs.shape}\")"
      ],
      "metadata": {
        "id": "sJ1FxltHH79i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
        "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])"
      ],
      "metadata": {
        "id": "hwVPAy2VJR5v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}