{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5IojFjoPCXVLfWKh5TUMB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsong-77/transformer-practice/blob/main/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FitwZcD3ZbAl"
      },
      "outputs": [],
      "source": [
        "!pip install transformers===4.11.3\n",
        "!pip install datasets\n",
        "!pip install seqeval==1.2.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets\n",
        "from datasets import get_dataset_config_names\n",
        "\n",
        "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
        "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
      ],
      "metadata": {
        "id": "I50JkZhXXvOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load datasets\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict\n",
        "from datasets import DatasetDict\n",
        "\n",
        "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
        "fracs = [0.629, 0.229, 0.084, 0.059]\n",
        "panx_ch = defaultdict(DatasetDict)\n",
        "\n",
        "for lang, frac in zip(langs, fracs):\n",
        "  ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
        "  for split in ds:\n",
        "    panx_ch[lang][split] = ds[split].shuffle(seed=0).select(range(int(frac * ds[split].num_rows)))\n",
        "\n",
        "panx_ch"
      ],
      "metadata": {
        "id": "WiKaHxy3ZNLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs}, index=[\"Number of training examples\"])"
      ],
      "metadata": {
        "id": "rUH3PmSDbntV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add ner tags str\n",
        "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
        "print(tags)\n",
        "\n",
        "def create_tag_names(batch):\n",
        "  return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
        "\n",
        "panx_de = panx_ch[\"de\"].map(create_tag_names)\n",
        "panx_de[\"train\"][0]"
      ],
      "metadata": {
        "id": "KvdJTAlBeF4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "split2freqs = defaultdict(Counter)\n",
        "for split, dataset in panx_de.items():\n",
        "  for row in dataset[\"ner_tags_str\"]:\n",
        "    for tag in row:\n",
        "      if tag.startswith(\"B\"):\n",
        "        tag_type = tag.split(\"-\")[1]\n",
        "        split2freqs[split][tag_type] += 1\n",
        "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
      ],
      "metadata": {
        "id": "CVhdzs4OfgSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "xlmr_model_name = \"xlm-roberta-base\"\n",
        "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
      ],
      "metadata": {
        "id": "yPV_6ugnoyTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(batch):\n",
        "  tokenized_inputs = xlmr_tokenizer(batch[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "\n",
        "  labels = []\n",
        "  for idx, label in enumerate(batch[\"ner_tags\"]):\n",
        "    word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "    for word_idx in word_ids:\n",
        "      if word_idx is None or word_idx == previous_word_idx:\n",
        "        label_ids.append(-100)\n",
        "      else:\n",
        "        label_ids.append(label[word_idx])\n",
        "      previous_word_idx = word_idx\n",
        "    labels.append(label_ids)\n",
        "    \n",
        "  tokenized_inputs[\"labels\"] = labels\n",
        "  return tokenized_inputs"
      ],
      "metadata": {
        "id": "ESYJgNEnEnBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_panx_dataset(corpus):\n",
        "  return corpus.map(tokenize_and_align_labels, batched=True, remove_columns=['langs', 'ner_tags', 'tokens'])\n",
        "\n",
        "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])\n",
        "panx_de_encoded[\"train\"][0]"
      ],
      "metadata": {
        "id": "2aydTqzPKsay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaConfig\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
        "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
        "\n",
        "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
        "  config_class = XLMRobertaConfig\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super().__init__(config)\n",
        "    self.num_labels = config.num_labels\n",
        "    # model\n",
        "    self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
        "    # classification head\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    # weights\n",
        "    self.init_weights()\n",
        "\n",
        "  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
        "    # encode\n",
        "    outputs = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **kwargs)\n",
        "    # classify\n",
        "    sequence_output = self.dropout(outputs[0])\n",
        "    logits = self.classifier(sequence_output)\n",
        "    # losses\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "    #output\n",
        "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)"
      ],
      "metadata": {
        "id": "BMsq1AnOuRX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoConfig\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
        "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}\n",
        "\n",
        "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,\n",
        "                                         num_labels=tags.num_classes,\n",
        "                                         id2label=index2tag, label2id=tag2index)\n",
        "                                         \n",
        "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
      ],
      "metadata": {
        "id": "XGGhmyLqFRK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from seqeval.metrics import f1_score\n",
        "\n",
        "def align_predictions(predictions, label_ids):\n",
        "  preds = np.argmax(predictions, axis=2)\n",
        "  batch_size, seq_len = preds.shape\n",
        "\n",
        "  labels_list, preds_list = [], []\n",
        "  for batch_idx in range(batch_size):\n",
        "    example_labels, example_preds = [], []\n",
        "    for seq_idx in range(seq_len):\n",
        "      if label_ids[batch_idx, seq_idx] != -100:\n",
        "        example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
        "        example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
        "    labels_list.append(example_labels)\n",
        "    preds_list.append(example_preds)\n",
        "\n",
        "  return preds_list, labels_list\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  y_pred, y_true = align_predictions(eval_pred.predictions, eval_pred.label_ids)\n",
        "  return {\"f1\": f1_score(y_true, y_pred)}"
      ],
      "metadata": {
        "id": "dC7wPOXP_N7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "num_epochs = 3\n",
        "batch_size = 24\n",
        "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
        "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
        "training_args = TrainingArguments(output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs,\n",
        "                                  per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size,\n",
        "                                  evaluation_strategy=\"epoch\", save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps, push_to_hub=False)\n",
        "\n",
        "def model_init():\n",
        "    return XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config=xlmr_config).to(device)"
      ],
      "metadata": {
        "id": "byknJikQCqEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model_init=model_init, args=training_args,\n",
        "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
        "                  train_dataset=panx_de_encoded[\"train\"],\n",
        "                  eval_dataset=panx_de_encoded[\"validation\"],\n",
        "                  tokenizer=xlmr_tokenizer)\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "9y3U_zNiIKxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# error analysis\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "def forward_pass_with_label(batch):\n",
        "  features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
        "  batch = data_collator(features)\n",
        "  input_ids = batch[\"input_ids\"].to(device)\n",
        "  attention_mask = batch[\"attention_mask\"].to(device)\n",
        "  labels = batch[\"labels\"].to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    output = trainer.model(input_ids, attention_mask)\n",
        "    predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
        "\n",
        "  loss = cross_entropy(output.logits.view(-1, 7), labels.view(-1), reduction=\"none\")\n",
        "  loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
        "\n",
        "  return {\"loss\":loss, \"predicted_label\": predicted_label}"
      ],
      "metadata": {
        "id": "uMnfA9jSwgeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_set = panx_de_encoded[\"validation\"]\n",
        "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
        "df = valid_set.to_pandas()"
      ],
      "metadata": {
        "id": "TwvYPI4nx5Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index2tag[-100] = \"IGN\"\n",
        "df[\"input_tokens\"] = df[\"input_ids\"].apply(lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\n",
        "df[\"predicted_label\"] = df[\"predicted_label\"].apply(lambda x: [index2tag[i] for i in x])\n",
        "df[\"labels\"] = df[\"labels\"].apply(lambda x: [index2tag[i] for i in x])\n",
        "df['loss'] = df.apply(lambda x: x['loss'][:len(x['input_ids'])], axis=1)\n",
        "df['predicted_label'] = df.apply(lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n",
        "df.head(1)"
      ],
      "metadata": {
        "id": "a0f38Hcdyhok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# token level\n",
        "df_tokens = df.apply(pd.Series.explode)\n",
        "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
        "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
        "df_tokens.head(7)"
      ],
      "metadata": {
        "id": "s77SFSWtyquo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
        "             .agg([\"count\", \"mean\", \"sum\"])\n",
        "             .droplevel(level=0, axis=1)\n",
        "             .sort_values(by=\"sum\", ascending=False)\n",
        "             .reset_index()\n",
        "             .round(2)\n",
        "             .head(10)\n",
        "             .T\n",
        ")"
      ],
      "metadata": {
        "id": "5mujlOnj0uD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
        "             .agg([\"count\", \"mean\", \"sum\"])\n",
        "             .droplevel(level=0, axis=1)\n",
        "             .sort_values(by=\"mean\", ascending=False)\n",
        "             .reset_index()\n",
        "             .round(2)\n",
        "             .T\n",
        ")"
      ],
      "metadata": {
        "id": "nR0G_a7l2xZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "  cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
        "  fig, ax = plt.subplots(figsize=(6, 6))\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "  disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "  plt.title(\"Normalized confusion matrix\")\n",
        "  plt.show()\n",
        "\n",
        "plot_confusion_matrix(df_tokens[\"predicted_label\"], df_tokens[\"labels\"], tags.names)"
      ],
      "metadata": {
        "id": "T6ob1xY37ZiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence level\n",
        "def get_samples(df):\n",
        "  for _, row in df.iterrows():\n",
        "    labels, preds, tokens, losses = [], [], [], []\n",
        "    for i, mask in enumerate(row[\"attention_mask\"]):\n",
        "      if i not in {0, len(row[\"attention_mask\"])}:\n",
        "        labels.append(row[\"labels\"][i])\n",
        "        preds.append(row[\"predicted_label\"][i])\n",
        "        tokens.append(row[\"input_tokens\"][i])\n",
        "        losses.append(f\"{row['loss'][i]:.2f}\")\n",
        "    df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels, \"preds\": preds, \"losses\": losses}).T\n",
        "    yield df_tmp\n",
        "\n",
        "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
        "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
        "\n",
        "for sample in get_samples(df_tmp):\n",
        "    display(sample)"
      ],
      "metadata": {
        "id": "IGbrDWUV9MyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross-lingual transfer\n",
        "def get_f1_score(trainer, dataset):\n",
        "  return trainer.predict(dataset).metrics[\"test_f1\"]\n",
        "\n",
        "def evaluate_lang_performance(lang, trainer):\n",
        "  panx_ds = encode_panx_dataset(panx_ch[lang])\n",
        "  return get_f1_score(trainer, panx_ds[\"test\"])\n",
        "\n",
        "f1_scores = defaultdict(dict)\n",
        "\n",
        "f1_scores[\"de\"][\"de\"] = evaluate_lang_performance(\"de\", trainer)\n",
        "print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.3f}\")\n",
        "\n",
        "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer)\n",
        "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")\n",
        "\n",
        "f1_scores[\"de\"][\"en\"] = evaluate_lang_performance(\"en\", trainer)\n",
        "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")"
      ],
      "metadata": {
        "id": "dJbsmnnOF93U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine-tuning on one corpus\n",
        "\n",
        "def train_on_subset(dataset, num_samples):\n",
        "  train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
        "  valid_ds = dataset[\"validation\"]\n",
        "  test_ds = dataset[\"test\"]\n",
        "  training_args.logging_steps = len(train_ds) // batch_size\n",
        "\n",
        "  trainer = Trainer(model_init=model_init, args=training_args,\n",
        "                    data_collator=data_collator, compute_metrics=compute_metrics,\n",
        "                    train_dataset=train_ds, eval_dataset=valid_ds,\n",
        "                    tokenizer=xlmr_tokenizer)\n",
        "  trainer.train()\n",
        "\n",
        "  f1_score = get_f1_score(trainer, test_ds)\n",
        "  return pd.DataFrame.from_dict({\"num_samples\": [len(train_ds)], \"f1_score\": [f1_score]})"
      ],
      "metadata": {
        "id": "ebtjjpnFKXNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "panx_fr_encoded = encode_panx_dataset(panx_ch[\"fr\"])\n",
        "metrics_df = train_on_subset(panx_fr_encoded, 250)"
      ],
      "metadata": {
        "id": "_Yp1_ZCYL4-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for num_samples in [500, 1000, 2000, 4000]:\n",
        "  metrics_df = metrics_df.append(train_on_subset(panx_fr_encoded, num_samples), ignore_index=True)"
      ],
      "metadata": {
        "id": "CbQ49ONPMlVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.axhline(f1_scores[\"de\"][\"fr\"], ls=\"--\", color=\"r\")\n",
        "metrics_df.set_index(\"num_samples\").plot(ax=ax)\n",
        "plt.legend([\"Zero-shot from de\", \"Fine-tuned on fr\"], loc=\"lower right\")\n",
        "plt.ylim((0, 1))\n",
        "plt.xlabel(\"Number of Training Samples\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BZvKz1faM7wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "def concatenate_splits(corpora):\n",
        "  multi_corpus = DatasetDict()\n",
        "  for split in corpora[0].keys():\n",
        "    multi_corpus[split] = concatenate_datasets([corpus[split] for corpus in corpora]).shuffle(seed=42)\n",
        "\n",
        "  return multi_corpus\n",
        "\n",
        "panx_de_fr_encoded = concatenate_splits([panx_de_encoded, panx_fr_encoded])\n",
        "panx_de_fr_encoded"
      ],
      "metadata": {
        "id": "lSJhULQ2NsAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args.logging_steps = len(panx_de_fr_encoded[\"train\"]) // batch_size\n",
        "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-de-fr\"\n",
        "\n",
        "trainer = Trainer(model_init=model_init, args=training_args,\n",
        "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
        "                  tokenizer=xlmr_tokenizer,\n",
        "                  train_dataset=panx_de_fr_encoded[\"train\"], eval_dataset=panx_de_fr_encoded[\"validation\"])\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "w79Cc0DROaUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in langs:\n",
        "  f1 = evaluate_lang_performance(lang, trainer)\n",
        "  print(f\"F1-score of [de-fr] model on [{lang}] dataset: {f1:.3f}\")"
      ],
      "metadata": {
        "id": "2IiiOpkxOw0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpora = [panx_de_encoded]\n",
        "\n",
        "for lang in langs[1:]:\n",
        "  training_args.out_dir = f\"xlm-roberta-base-finetuned-panx-{lang}\"\n",
        "  ds_encoded = encode_panx_dataset(panx_ch[lang])\n",
        "  metrics = train_on_subset(ds_encoded, ds_encoded[\"train\"].num_rows)\n",
        "  f1_scores[lang][lang] = metrics[\"f1_score\"][0]\n",
        "  corpora.append(ds_encoded)"
      ],
      "metadata": {
        "id": "PCIZ9XJZPYk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine-tuning on multiple languages at once\n",
        "corpora_encoded = concatenate_splits(corpora)\n",
        "\n",
        "training_args.logging_steps = len(corpora_encoded[\"train\"]) // batch_size\n",
        "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-all\"\n",
        "\n",
        "trainer = Trainer(model_init=model_init, args=training_args,\n",
        "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
        "                  tokenizer=xlmr_tokenizer,\n",
        "                  train_dataset=corpora_encoded[\"train\"], eval_dataset=corpora_encoded[\"validation\"])\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "yujbakYkQytY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, lang in enumerate(langs):\n",
        "  f1_scores[\"all\"][lang] = get_f1_score(trainer, corpora[idx][\"test\"])\n",
        "\n",
        "scores_data = {\"de\": f1_scores[\"de\"],\n",
        "               \"each\": {lang: f1_scores[lang][lang] for lang in langs},\n",
        "               \"all\": f1_scores[\"all\"]}\n",
        "\n",
        "f1_scores_df = pd.DataFrame(scores_data).T.round(4)\n",
        "f1_scores_df.rename_axis(index=\"Fine-tune on\", columns=\"Evaluated on\", inplace=True)\n",
        "f1_scores_df"
      ],
      "metadata": {
        "id": "nZyF5x69Real"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}